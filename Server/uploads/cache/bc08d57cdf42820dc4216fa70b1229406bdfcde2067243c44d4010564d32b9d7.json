"Artificial Intelligence\nTE AI&DS\nSemester V\nExperiment\nAim: Implement a Local Search Technique (Hill Climbing)\nTheory:\nLocal search techniques are optimization methods that operate by exploring\nneighboring solutions to iteratively improve a current solution. Unlike exhaustive\nsearches, local search techniques are efficient for solving large problems by\nfocusing only on local changes rather than searching the entire problem space.\nHill Climbing is one such local search technique where the algorithm starts with an\narbitrary solution and iteratively improves by selecting neighboring solutions with a\nbetter objective value. The process continues until no better neighbors are found,\nindicating that a local optimum has been reached.\n\u2022\nGoal: Maximize or minimize a given objective function.\n\u2022\nChallenge: Hill climbing may get stuck in local maxima or plateaus, which\nare not necessarily the global optimum.\nName: Hringkesh Singh\nBatch: T2-2\nRoll Number: 2201104\nArtificial Intelligence\nTE AI&DS\nSemester V\nAlgorithm:\nInitialization: Start with an initial random solution.\nEvaluation: Evaluate the objective function for the current solution.\nGenerate Neighbors: Generate all neighboring solutions by making small\nmodifications to the current solution.\nSelect Best Neighbor: Choose the neighbor with the highest improvement.\nTermination: Repeat the process until no better neighbors exist (local optimum is\nreached).\nCode:\nimport random\ndef hill_climbing(objective_function, solution, max_iterations=100, tolerance=1e-6,\nrestarts=0):\ncurrent_solution = solution\ncurrent_value = objective_function(current_solution)\nfor _ in range(max_iterations):\nneighbors = generate_neighbors(current_solution)\nbest_neighbor = current_solution\nbest_value = current_value\n# Explore neighbors\nName: Hringkesh Singh\nBatch: T2-2\nRoll Number: 2201104\nArtificial Intelligence\nTE AI&DS\nSemester V\nfor neighbor in neighbors:\nneighbor_value = objective_function(neighbor)\nif neighbor_value > best_value:\nbest_value = neighbor_value\nbest_neighbor = neighbor\n# If no improvement, stop\nif abs(best_value - current_value) < tolerance:\nbreak\ncurrent_solution = best_neighbor\ncurrent_value = best_value\n# Optionally, perform random restarts to avoid local optima\nif restarts > 0:\nreturn random_restart(objective_function, max_iterations, tolerance, restarts,\ncurrent_solution, current_value)\nreturn current_solution, current_value\ndef generate_neighbors(solution, step_size=1):\n\"\"\"Generates neighbors by adding or subtracting step_size from the solution\"\"\"\nName: Hringkesh Singh\nBatch: T2-2\nRoll Number: 2201104\nArtificial Intelligence\nTE AI&DS\nSemester V\nreturn [solution + step_size, solution - step_size]\ndef objective_function(x):\n\"\"\"Example objective function: A quadratic function with a maximum\"\"\"\nreturn -x**2 + 10*x + 5\ndef random_restart(objective_function, max_iterations, tolerance, restarts,\nbest_solution, best_value):\nfor _ in range(restarts):\ninitial_solution = random.randint(-10, 10)\nnew_solution, new_value = hill_climbing(objective_function, initial_solution,\nmax_iterations, tolerance)\nif new_value > best_value:\nbest_solution, best_value = new_solution, new_value\nreturn best_solution, best_value\n# Run the hill climbing algorithm\ninitial_solution = random.randint(-10, 10)\nresult, value = hill_climbing(objective_function, initial_solution, max_iterations=100,\ntolerance=1e-6, restarts=5)\nprint(f\"Optimal solution: {result}, Objective value: {value}\")\nName: Hringkesh Singh\nBatch: T2-2\nRoll Number: 2201104\nArtificial Intelligence\nTE AI&DS\nSemester V\nOutput:\nConclusion:\nIn this experiment, the Hill Climbing algorithm was successfully implemented as a\nlocal search technique.\nLO3, LO6 mapped.\nName: Hringkesh Singh\nBatch: T2-2\nRoll Number: 2201104\n"